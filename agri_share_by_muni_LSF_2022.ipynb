{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the percent share of agriculture in total employment per municipality or province for the year 2022 (PSA Labor Force Survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Combine all csv files in folder into one DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import glob module to find files in directory\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all csv filenames in list\n",
    "file_list = glob.glob(r\"L*.csv\")\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe to store all combined DFs\n",
    "lfs_2022_df = pd.DataFrame()\n",
    "\n",
    "# Define function to check if column name...\n",
    "# ...contains 'REG', 'WORK', 'PROVMUN', or 'PKB'\n",
    "def check_str(col_name):\n",
    "     substrs = ['REG','_WORK', '_PROVMUN', '_PKB']\n",
    "     return any(x in col_name for x in substrs)\n",
    "\n",
    "# For each csv file in folder...\n",
    "for fp in file_list:\n",
    "    # ...read into a DF, w/ specified cols & NaN values...\n",
    "    df = pd.read_csv(fp, usecols=check_str,\n",
    "                    na_values=[' ', '  ', '   ', '    ', '     ', '      '])\n",
    "    \n",
    "    # ...then append to empty DF for whole year\n",
    "    lfs_2022_df = pd.concat([lfs_2022_df, df], ignore_index=True)\n",
    "    \n",
    "# Display head of merged DF\n",
    "lfs_2022_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Merge all alike columns and drop extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine first 20 rows where PUFC11_WORK is not null\n",
    "lfs_2022_df.loc[~lfs_2022_df['PUFC11_WORK'].isnull()].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all rows where PUFC11_WORK is null, copy values from PUFC09_WORK and PUFC09A_WORK\n",
    "lfs_2022_df.loc[lfs_2022_df['PUFC11_WORK'].isnull(), 'PUFC11_WORK'] =\\\n",
    "    lfs_2022_df['PUFC09_WORK']\n",
    "\n",
    "lfs_2022_df.loc[lfs_2022_df['PUFC11_WORK'].isnull(), 'PUFC11_WORK'] =\\\n",
    "    lfs_2022_df['PUFC09A_WORK']\n",
    "\n",
    "lfs_2022_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra WORK columns\n",
    "lfs_2022_df = lfs_2022_df.drop(['PUFC09_WORK', 'PUFC09A_WORK'], axis=1)\n",
    "lfs_2022_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat Step 3 for PROVMUN and PKB columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all rows where PUFC12A_PROVMUN is null, copy values from PUFC11A_PROVMUN\n",
    "lfs_2022_df.loc[lfs_2022_df['PUFC12A_PROVMUN'].isnull(), 'PUFC12A_PROVMUN'] =\\\n",
    "    lfs_2022_df['PUFC11A_PROVMUN']\n",
    "\n",
    "lfs_2022_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all rows where PUFC6_PKB is null, copy values from PUFC15_PKB\n",
    "lfs_2022_df.loc[lfs_2022_df['PUFC16_PKB'].isnull(), 'PUFC16_PKB'] =\\\n",
    "    lfs_2022_df['PUFC15_PKB']\n",
    "\n",
    "lfs_2022_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra PROVMUN and PKB columns\n",
    "lfs_2022_df = lfs_2022_df.drop(['PUFC11A_PROVMUN', 'PUFC15_PKB'], axis=1)\n",
    "lfs_2022_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Save to new DF only the rows where WORK = 1 (employed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_df = lfs_2022_df.loc[lfs_2022_df['PUFC11_WORK'] == 1]\n",
    "work_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Rename columns and drop work indicator column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = {\n",
    "    'PUFREG': 'REGION',\n",
    "    'PUFC12A_PROVMUN': 'PROV_MUN',\n",
    "    'PUFC16_PKB': 'INDUSTRY'\n",
    "}\n",
    "\n",
    "work_df = work_df.rename(columns=col_names)[['REGION', 'PROV_MUN', 'INDUSTRY']]\n",
    "work_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Parse province out of PROV_MUN column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove decimal place from prov-muni by converting to int\n",
    "work_df['PROV_MUN'] = work_df['PROV_MUN'].astype(int)\n",
    "\n",
    "# Convert to string, pad w/ leading zeroes up to 4 chars,\n",
    "# then slice out first 2 chars as province code\n",
    "work_df['PROVINCE'] = work_df['PROV_MUN'].astype(str)\\\n",
    "                      .str.zfill(4).str.slice(0,2)\n",
    "\n",
    "work_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique municipality codes\n",
    "len(work_df['PROV_MUN'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique province codes\n",
    "len(work_df['PROVINCE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Group DF by municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_muni = work_df.groupby('PROV_MUN')\n",
    "len(by_muni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Calculate percent share of agriculture in total employment per municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe for aggregated values\n",
    "agshare_by_muni = pd.DataFrame()\n",
    "\n",
    "# Iterate over ach municipality\n",
    "for key, group in by_muni:\n",
    "\n",
    "    # Create empty series to store each calculation\n",
    "    c = pd.Series()\n",
    "\n",
    "    # Add region & muni code to series of values\n",
    "    c['REGION'] = group['REGION'].median().astype(int)\n",
    "    c['PROVINCE'] = group['PROVINCE'].astype(int).median()\n",
    "    c['PROV_MUN'] = key\n",
    "\n",
    "    # Count total number of employed (i.e. length per group)\n",
    "    c['TOTAL_EMPLOYED'] = group['INDUSTRY'].count()\n",
    "\n",
    "    # Count number of people employed in agriculture\n",
    "    c['AGRI_EMPLOYED'] = group.loc[group['INDUSTRY'] < 4, 'INDUSTRY'].count()\n",
    "\n",
    "    # Calculate ratio between agri & total employment\n",
    "    # and round off values to 2 decimal places\n",
    "    c['PERCENT_AGRI'] = c['AGRI_EMPLOYED'] / c['TOTAL_EMPLOYED'] * 100\n",
    "    c['PERCENT_AGRI'] = round(c['PERCENT_AGRI'], 2)\n",
    "\n",
    "    # Convert series into dataframe and transpose into a row\n",
    "    row = c.to_frame().transpose()\n",
    "\n",
    "    # Append new row into agshare_by_muni dataframe\n",
    "    agshare_by_muni = pd.concat([agshare_by_muni, row], ignore_index=True)\n",
    "\n",
    "agshare_by_muni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9: Read metadata file into DF of province & municipality names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata xlsx file as DF\n",
    "\n",
    "names_fp = r\"lfs_november_2022_metadata(dictionary).xlsx\"\n",
    "\n",
    "geo_names = pd.read_excel(names_fp, sheet_name=r\"lfs_november_2022_valueset\",\n",
    "                          skiprows=168, skipfooter=284)\n",
    "\n",
    "# Define dict to rename columns\n",
    "new_cols = {\n",
    "    'Unnamed: 2': 'LOCATION',\n",
    "    'Unnamed: 3': 'LOC_CODE'\n",
    "}\n",
    "\n",
    "geo_names = geo_names.rename(columns=new_cols)[['LOCATION', 'LOC_CODE']]\n",
    "\n",
    "geo_names.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split LOCATION column into province and municipality\n",
    "names = geo_names['LOCATION'].str.split(' - ', expand=True)\n",
    "\n",
    "# Put first item of split list into PROV_NAME column\n",
    "# But only get all chars after 4-digit code and space\n",
    "geo_names['PROV_NAME'] = names[0].str.slice(start=6)\n",
    "\n",
    "# Put second item of split list into MUN_NAME column\n",
    "geo_names['MUN_NAME'] = names[1]\n",
    "\n",
    "geo_names.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded LOCATION column\n",
    "geo_names.drop(columns=['LOCATION'], inplace=True)\n",
    "\n",
    "geo_names.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: Join names DF with employment DF (on muni code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agshare_by_muni = agshare_by_muni.merge(right=geo_names, left_on='PROV_MUN', right_on='LOC_CODE')\n",
    "\n",
    "agshare_by_muni.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove parentheticals from province & municipality names\n",
    "agshare_by_muni['PROV_NAME'] = agshare_by_muni['PROV_NAME'].str.replace(r\"\\(.+\\)\", \"\")\n",
    "\n",
    "agshare_by_muni.loc[agshare_by_muni['PROVINCE'] == 60].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
